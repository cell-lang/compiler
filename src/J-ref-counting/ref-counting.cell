// RIGHT NOW IMPLICIT PARAMETERS ARE INCLUDED IN THE LIST OF LIVE VAR.
// THAT'S WRONG, THEY ARE JUST LIKE EXTERNAL VARS, THEY ARE ALWAYS LIVE


BoolProcDef add_ref_counting(BoolProcDef proc_def) = proc_def;


ObjProcDef add_ref_counting(ObjProcDef proc_def) =
  obj_proc_def(
    name:           proc_def.name,
    type:           proc_def.type,
    args:           proc_def.args,
    ret_val_repr:   proc_def.ret_val_repr,
    impl_args:      proc_def.impl_args,
    loc_auto_vars:  proc_def.loc_auto_vars,
    loc_db_vars:    proc_def.loc_db_vars,
    body:           nonempty(add_ref_counting(proc_def.body)),
    cached:         proc_def.cached
  );


ReactBlock add_ref_counting(ReactBlock block) =
  react_block(
    name:                 block.name,
    ord_inputs:           block.ord_inputs,
    ord_outputs:          block.ord_outputs,
    input_memb_preds:     block.input_memb_preds,
    inputs:               block.inputs,
    outputs:              block.outputs,
    memb_vars:            block.memb_vars,
    nested_auto_vars:     block.nested_auto_vars,
    nested_static_blocks: block.nested_static_blocks,
    pre_init_code:        add_ref_counting(block.pre_init_code),
    cleanup_code:         block.cleanup_code,
    nodes_update_code:    [id -> add_ref_counting(c) : id c <- block.nodes_update_code],
    apply_code:           add_ref_counting(block.apply_code),
    queue_update_code:    block.queue_update_code,
    state_is_def_code:    block.state_is_def_code,
    copy_state_code:      add_ref_counting(block.copy_state_code),
    set_state_code:       add_ref_counting(block.set_state_code),
    methods:              [ id -> compiled_method(m.args_types, m.args_memb_preds, m.ret_type, add_ref_counting(m.code))
                            : id m <- block.methods
                          ],
    const_data:           block.const_data,
    time_rules_count:     block.time_rules_count,
    state_memb_pred:      block.state_memb_pred
  );


StaticBlock add_ref_counting(StaticBlock block) =
  static_block(
    name:             block.name,
    links:            block.links,
    state_vars:       block.state_vars,
    nested_blocks:    block.nested_blocks,
    value_stores:     block.value_stores,
    tables:           block.tables,
    init_code:        add_ref_counting(block.init_code),
    cleanup_code:     add_ref_counting(block.cleanup_code),
    copy_state_code:  add_ref_counting(block.copy_state_code),
    set_state_code:   add_ref_counting(block.set_state_code),
    methods:          [ id -> compiled_method(m.args_types, m.args_memb_preds, m.ret_type, add_ref_counting(m.code))
                        : id m <- block.methods
                      ],
    updates_code:     [id -> add_ref_counting(c) : id c <- block.updates_code],
    msg_memb_pred:    block.msg_memb_pred,
    state_memb_pred:  block.state_memb_pred
  );

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

() add_ref_counting(()) = ();

Instr+ add_ref_counting(Instr+ instrs) {
  leaf_nodes, code_tree = build_root_code_graph(instrs);
  flow_map = build_flow_map(code_tree, leaf_nodes);
  no_end_node_flow_map = ((n : n <- ns, n != end_node) : ns <- flow_map);
  rev_flow_map = reverse_flow_map(no_end_node_flow_map);
  live_vars_before_map, live_vars_after_map = build_live_vars_maps(leaf_nodes, no_end_node_flow_map);
  // ref_live_vars_before_map, ref_live_vars_after_map = ref_build_live_vars_maps(leaf_nodes, flow_map);
  entry_vars_states = entry_vars_states(leaf_nodes, no_end_node_flow_map, live_vars_after_map);
  // ref_entry_vars_states = ref_entry_vars_states(leaf_nodes, flow_map, live_vars_after_map);
  assert {
    before_info = zip(live_vars_before_map, entry_vars_states);
    uninit_vars = ([v : v <- lvs, not is_initialized(vs, v)] : lvs, vs <- before_info);
    is_ok = none((vs != [] : vs <- uninit_vars));
    if not is_ok {
      print "***********************************************";
      print uninit_vars;
      for vs @ i <- uninit_vars {
        if vs != [] {
          print "* * * * * * * * * * *";
          print vs;
          print live_vars_before_map(i);
          print entry_vars_states(i);
        }
      }
    }
    return is_ok;
  };
  let flow_map=flow_map, live_vars_after_map=live_vars_after_map, entry_vars_states=entry_vars_states
    rc_nodes = (add_ref_counting(n, i) : n @ i <- leaf_nodes);
  return ref_count_closures(nonempty(reconstruct(code_tree, rc_nodes)));
}

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

// We need to calculate a target variables state before each statement.
// Once we have one, we can decide what reference counting instructions
// We need to insert when going from one state to the next.

// This variable state depends on the release strategy. What are the
// alternatives?

//   - Greedy release: we release variables as soon as they are not needed anymore.
//     + memory is released as soon as possible
//     + the reference count on an object is always as low as can be,
//       and that can help with functional updates
//     + when a path forks, we end up doing a common release just once before the fork

//   - Lazy release: we release variables at the last possible chance to do so.
//     + when multiple code paths converge to a single node, we can do a common
//       release just once
//     + no need to release memory before a terminate statement. (NOT SURE HERE...)

// Let's say we go with the lazy release strategy.

VarsState* entry_vars_states(NodeInfo* leaf_nodes, Nat** flow_map, [TrkVar]* live_vars_after_map) {
  len = |leaf_nodes|;

  rev_flow_map = reverse_flow_map(flow_map);
  fwd_nodes_map = ([n : n <- ns, n < i] : ns @ i <- rev_flow_map);

  entry_states = (blank_vars_state);
  for i = 1..len {
    fwd_nodes = fwd_nodes_map(i);
    fwd_states = [exit_vars_state_only(leaf_nodes(n), entry_states(n), live_vars_after_map(n)) : n <- fwd_nodes];
    entry_states = (entry_states | reconcile(fwd_states));
  }

  exit_states = (exit_vars_state_only(leaf_nodes(i), entry_state, live_vars_after_map(i)) : entry_state @ i <- entry_states);

  updated_map = len * (true);
  while any(updated_map) {
    new_entry_states = (blank_vars_state);
    new_exit_states = (exit_states(0));
    new_updated_map = (false);
    for i = 1..len {
      nodes = rev_flow_map(i);
      if (n <- nodes : if n < i then new_updated_map(n) else updated_map(n)) {
        states = [if n < i then new_exit_states(n) else exit_states(n) : n <- nodes];
        new_entry_state = reconcile(states);
        new_exit_state = exit_vars_state_only(leaf_nodes(i), new_entry_state, live_vars_after_map(i));
        updated = new_entry_state != entry_states(i);
      }
      else {
        new_entry_state = entry_states(i);
        new_exit_state = exit_states(i);
        updated = false;
      }
      new_entry_states = (new_entry_states | new_entry_state);
      new_exit_states = (new_exit_states | new_exit_state);
      new_updated_map = (new_updated_map | updated);
    }
    entry_states = new_entry_states;
    exit_states = new_exit_states;
    updated_map = new_updated_map;
  }

  return entry_states;
}


// [VarsState] ref_entry_vars_states([NodeInfo] leaf_nodes, [[Nat]] flow_map, [TrkVar*] live_vars_after_map)
// {
//   len = |leaf_nodes|;

//   rev_flow_map = reverse_flow_map(flow_map);
//   fwd_nodes_map = [{n : n <- ns, n < i} : ns @ i <- rev_flow_map];

//   entry_states = [blank_vars_state];
//   for (i = 1..len)
//     fwd_nodes = fwd_nodes_map(i);
//     fwd_states = {exit_vars_state_only(leaf_nodes[n], entry_states[n], live_vars_after_map[n]) : n <- fwd_nodes};
//     entry_states = [entry_states | reconcile(fwd_states)];
//   ;

//   loop
//     new_entry_states = [blank_vars_state];
//     for (i = 1..len)
//       nodes = rev_flow_map(i);
//       states = {exit_vars_state_only(leaf_nodes[n], entry_states[n], live_vars_after_map[n]) : n <- nodes};
//       new_entry_states = [new_entry_states | reconcile(states)];
//     ;
//     break if new_entry_states == entry_states;
//     entry_states = new_entry_states;
//   ;

//   return entry_states;
// }

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

implicit flow_map : NodeId**, live_vars_after_map : [TrkVar]*, entry_vars_states : VarsState* {
  RCNodeInfo add_ref_counting(NodeInfo info, Nat idx) {
    entry_state = entry_vars_states(idx);
    exit_state, pre_instrs, post_instrs = exit_vars_state(info, entry_state, live_vars_after_map(idx));
    return add_ref_counting(info, flow_map(idx), entry_state, exit_state, pre_instrs, post_instrs);
  }


  RCNodeInfo add_ref_counting(NodeInfo info, NodeId* next_nodes, VarsState entry_state, VarsState exit_state, Instr* pre_instrs, Instr* post_instrs) =
    std_node(terminate)                     = std_node((terminate)),
    std_node(ret_val(e?))                   = {assert post_instrs == (); return rc_ret_node(e, entry_state, pre_instrs);},
    ## THIS PATTERN IS PRETTY UGLY...
    std_node(break_loop i? | exit_block i?) = { assert pre_instrs == () and post_instrs == ();
                                                return rc_break_or_exit_node(i, only_unsafe(next_nodes), exit_state);
                                              },
    std_node(i?)                            = rc_std_node(i, only_unsafe(next_nodes), exit_state, pre_instrs, post_instrs),
    branch_node(c?)                         = { assert pre_instrs == () and post_instrs == ();
                                                fail if not next_nodes :: (NodeId, NodeId);
                                                return rc_branch_node(c, left(next_nodes), right(next_nodes), exit_state);
                                              },
    nat_switch_node(v?)                     = { assert pre_instrs == () and post_instrs == ();
                                                return rc_nat_switch_node(v, nonempty(next_nodes), exit_state);
                                              },
    symb_switch_node()                      = { assert pre_instrs == () and post_instrs == ();
                                                return rc_symb_switch_node(info.value, info.cases, nonempty(next_nodes), exit_state);
                                              },
    set_cls_par_node()                      = { assert pre_instrs == () and post_instrs == ();
                                                return rc_set_cls_par_node(info.var, info.cls, only_unsafe(next_nodes), exit_state);
                                              };


  RCNodeInfo rc_ret_node(<AtomicExpr, AtomicBoolExpr> expr, VarsState entry_state, Instr* pre_instrs) { ## THE LAST PARAMETER SHOULD BE REMOVED BECAUSE IT'S RECALCULATED. IT IS ONLY USED FOR AN ASSERTION
    state, instrs = swallow_var(entry_state, maybe_var(expr), []);
    assert pre_instrs == instrs;
    pre_instrs_2 = gen_state_switch_code(state, blank_vars_state);
    return std_node(pre_instrs & pre_instrs_2 & (ret_val(expr)));
  }


  RCNodeInfo rc_break_or_exit_node(Instr instr, NodeId next_node, VarsState exit_state) {
    next_node_entry_state = entry_vars_state(next_node);
    state_switch_code = gen_state_switch_code(exit_state, next_node_entry_state);
    return std_node((state_switch_code | instr));
  }


  RCNodeInfo rc_std_node(Instr instr, NodeId next_node, VarsState exit_state, Instr* pre_instrs, Instr* post_instrs) {
    next_node_entry_state = entry_vars_state(next_node);
    post_instrs_2 = gen_state_switch_code(exit_state, next_node_entry_state);
    return std_node(pre_instrs & (instr) & post_instrs & post_instrs_2);
  }


  RCNodeInfo rc_branch_node(BoolExpr cond, NodeId if_next_node, NodeId then_next_node, VarsState exit_state) {
    if_branch_entry_state = entry_vars_state(if_next_node);
    then_branch_entry_state = entry_vars_state(then_next_node);
    if_branch_post_instrs = gen_state_switch_code(exit_state, if_branch_entry_state);
    then_branch_post_instrs = gen_state_switch_code(exit_state, then_branch_entry_state);
    return branch_node(cond, if_branch_post_instrs, then_branch_post_instrs);
  }


  RCNodeInfo rc_nat_switch_node(IntExpr idx, NodeId+ next_nodes, VarsState exit_state) {
    case_post_instrs = (gen_state_switch_code(exit_state, entry_vars_state(n)) : n <- next_nodes);
    return rc_nat_switch_node(idx, case_post_instrs);
  }


  RCNodeInfo rc_symb_switch_node(ObjExpr expr, [+SymbObj]+ cases, NodeId+ next_nodes, VarsState exit_state) {
    all_post_instrs = (gen_state_switch_code(exit_state, entry_vars_state(n)) : n <- next_nodes);
    cases_post_instrs = subseq(all_post_instrs, 0, :blank, 1);
    else_post_instrs = last(all_post_instrs);
    return rc_symb_switch_node(expr, cases, nonempty(cases_post_instrs), else_post_instrs);
  }


  RCNodeInfo rc_set_cls_par_node(ImplArg var, AnyLambdaExpr cls, NodeId next_node, VarsState exit_state) {
    next_node_entry_state = entry_vars_state(next_node);
    post_instrs = gen_state_switch_code(exit_state, next_node_entry_state);
    return set_cls_par_node(var, cls, post_instrs);
  }
}


implicit entry_vars_states : VarsState* {
  VarsState entry_vars_state(NodeId next_node) =
    if next_node == end_node
      then blank_vars_state
      else entry_vars_states(next_node);
}

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

()     ref_count_closures(())             = ();
Instr+ ref_count_closures(Instr+ instrs)  = (ref_count_closures_single_instruction(i) : i <- instrs);


Instr ref_count_closures_single_instruction(Instr instr) =
  call_proc()         = call_proc(
                          var:  instr.var if instr.var?,
                          name: instr.name,
                          args: (ref_count_closure(p) : p <- instr.args)
                        ),
  branch()            = branch(
                          instr.cond,
                          ref_count_closures(instr.when_true),
                          ref_count_closures(instr.when_false)
                        ),
  repeat(is?)         = repeat(ref_count_closures(is)),
  execute_block(is?)  = execute_block(ref_count_closures(is)),
  try_block()         = try_block(instr.var, ref_count_closures(instr.body)),
  _                   = instr;


AtomicExpr ref_count_closure(AtomicExpr expr) = expr; ## NOT THE BEST NAME IN THIS CASE...

AnyLambdaExpr ref_count_closure(AnyLambdaExpr cls) =
  cls_var()       |
  capt_cls_var()  = cls,
  lambda_expr()   = lambda_expr(
                      cls_def(cls.cls.arity, add_ref_counting(cls.cls.body)),
                      cls.capt_vars,
                      cls.capt_cls_vars
                    );
