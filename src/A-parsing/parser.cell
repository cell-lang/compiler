ParsingRule par_rule(ParsingRule rule)      = block_rule(parenthesis, rule);
ParsingRule bracket_rule(ParsingRule rule)  = block_rule(bracket, rule);
ParsingRule brace_rule(ParsingRule rule)    = block_rule(brace, rule);

ParsingRule empty_block_rule(ParType pt) = block_rule(pt, empty_rule);

ParsingRule comma_sep_seq(ParsingRule rule) = comma_sep_seq(rule, true);
ParsingRule opt_comma_sep_seq(ParsingRule rule) = comma_sep_seq(rule, false);
ParsingRule comma_sep_seq(ParsingRule rule, Bool nonempty) = rep_rule(rule, atomic_rule(comma), nonempty, false);
ParsingRule comma_sep_seq(ParsingRule rule, Nat min_count) = rep_rule(rule, min_count, atomic_rule(comma), false);

ParsingRule pipe_sep_seq(ParsingRule rule)      = rep_rule(rule, atomic_rule(pipe),      true, false);
ParsingRule dot_sep_seq(ParsingRule rule)       = rep_rule(rule, atomic_rule(dot),       true, false);
ParsingRule colon_sep_seq(ParsingRule rule)     = rep_rule(rule, atomic_rule(colon),     true, false);
ParsingRule semicolon_sep_seq(ParsingRule rule) = rep_rule(rule, atomic_rule(semicolon), true, false);

ParsingRule weird_semicolon_sep_seq(ParsingRule rule) =
  rule_seq((
    rule,
    rule_semicolon,
    rep_rule(rule, atomic_rule(semicolon), false, false)
  ));

ParsingRule rep_rule_seq(ParsingRule+ rs) = rep_rule(rule_seq(rs));
ParsingRule par_rule_seq(ParsingRule+ rs) = par_rule(rule_seq(rs));

////////////////////////////////////////////////////////////////////////////////

type ParserError  = unexpected_end_of_file(ParsingRule),
                    unexpected_token(found: AnnotatedToken, expected: TokenMatchingRule?),
                    all_choices_failed(best_match: Atom, error: ParserError),
                    neg_rule_match(rule: ParsingRule, match: ParserMatch, offset: Nat);

type ParserMatch  = parser_match(rule_match: RuleMatch, nodes_consumed: Nat, failure: ParserError?);

type ParserResult = Result[ParserMatch, ParserError];

////////////////////////////////////////////////////////////////////////////////

ParserError unexpected_end_of_file(ParsingRule r)                     = :unexpected_end_of_file(r);
ParserError unexpected_token(AnnotatedToken t)                        = unexpected_token(found: t);
ParserError unexpected_token(AnnotatedToken t, TokenMatchingRule r)   = unexpected_token(found: t, expected: r);
ParserError all_choices_failed(Atom n, ParserError e)                 = all_choices_failed(best_match: n, error: e);
ParserError neg_rule_match(ParsingRule r, ParserMatch m, Nat o)       = neg_rule_match(rule: r, match: m, offset: o);

ParserMatch parser_match(RuleMatch rm, Nat nsc) = parser_match(rule_match: rm, nodes_consumed: nsc);

ParserMatch parser_match(RuleMatch rm, Nat nsc, ParserError pe) =
  parser_match(rule_match: rm, nodes_consumed: nsc, failure: pe);

ParserMatch parser_match(RuleMatch rm, Nat nsc, Maybe[ParserError] mpe) =
  parser_match(rule_match: rm, nodes_consumed: nsc, failure: value(mpe) if mpe != nothing);

////////////////////////////////////////////////////////////////////////////////

Int index_of_last_matched_token(ParserError error, AnnotatedToken+ tokens) =
  ## THIS WAS ACTUALLY AN INTERESTING PROBLEM: THE LOSS OF INFORMATION
  ## MAKES IT IMPOSSIBLE TO DETERMINE THE CORRECT VALUE. HOW TO FIX THIS?
  unexpected_end_of_file()  = last(tokens).index,
  unexpected_token()        = error.found.index - 1,
  all_choices_failed()      = index_of_last_matched_token(error.error, tokens),
  neg_rule_match()          = error.offset - 1;


Maybe[ParserError] choose_error(Maybe[ParserError] current, ParserError new, AnnotatedToken+ tokens) {
  return just(new) if current == nothing;
  curr_idx = index_of_last_matched_token(value(current), tokens);
  new_idx = index_of_last_matched_token(new, tokens);
  return if new_idx > curr_idx then just(new) else current;
}

////////////////////////////////////////////////////////////////////////////////

Bool matches(TokenMatchingRule rule, PlainToken token) =
  lowercase_id,       lowercase_id()            = true,
  mixedcase_id,       mixedcase_id()            = true,
  uppercase_id,       uppercase_id()            = true,
  qualified_symbol,   qualified_symbol()        = true,
  integer,            <*..*>                    = true,
  float,              float_lit()               = true,
  string,             string()                  = true,
  date,               date()                    = true,
  time,               time()                    = true,
  unary_operator,     operator(op?)             = op :: UnaryOperator,
  binary_operator,    operator(op?)             = op :: BinaryOperator,
  builtin,            builtin()                 = true,
  qual_var,           qual_var()                = true,
  pref_lowercase_id,  pref_lowercase_id()       = true,
  time_span,          nanoseconds()             = true,
  keyword(kw?),       lowercase_id(a?)          = kw == a,
  _,                  _                         = rule :: LangSymb and rule == token;


ParserResult parse_all(ParsingRule rule, AnnotatedToken+ tokens, [Atom -> ParsingRule] rec_rules) {
  // Let's first try to run the quick and dirty parser, which does not keep track of errors
  matching_atomic_rules = (matching_atomic_rule(t.token) : t <- tokens);
  fast_res = fast_parse(rule, 0, tokens=tokens, rec_rules=rec_rules, tokens_count=|tokens|, matching_atomic_rules=matching_atomic_rules);
  if fast_res != :no_match {
    rule_match, nodes_consumed = fast_res;
    return success(parser_match(rule_match, nodes_consumed)) if nodes_consumed == |tokens|;
  }

  // Parsing has failed, now let's parse again using the slow,
  // error-preserving parser to find out exactly where the error was
  res = parse(rule, tokens, 0, rec_rules);
  return res if is_failure(res);
  mtc = get_result(res);
  nodes_consumed = mtc.nodes_consumed;
  assert nodes_consumed <= |tokens|;
  // return res if nodes_consumed == |tokens|;
  assert nodes_consumed != |tokens|; // If fast parsing failed, accurate parsing must fail too
  if mtc.failure? and index_of_last_matched_token(mtc.failure, tokens) > nodes_consumed
    err = mtc.failure;
  else
    err = unexpected_token(tokens(nodes_consumed));
  return failure(err);
}


// String rule_desc(ParsingRule r) =
//   empty_rule          = printed(r),
//   atomic_rule()       = printed(r),
//   optional_rule(sr?)  = "optional_rule(" & rule_desc(sr) & ")",
//   rule_seq(rs?)       = "rule_seq(...)",
//   rep_rule()          = "rep_rule(" & rule_desc(r.rule) & ", ...)",
//   rule_choice()       = "rule_choice(...)",
//   rule_neg(sr?)       = "rule_neg(" & rule_desc(sr) & ")",
//   // block_rule()        = "block_rule(" & rule_desc(r.rule) & ", ...)",
//   rule_ref()          = printed(r);


ParserResult parse(ParsingRule rule, AnnotatedToken+ tokens, Nat offset, [Atom -> ParsingRule] rec_rules) =
  empty_rule        = success(parser_match(null_match, 0)),
  atomic_rule(r?)   = parse_atomic_rule(r, tokens, offset, rec_rules),
  optional_rule(r?) = parse_optional_rule(r, tokens, offset, rec_rules),
  rule_seq(rs?)     = parse_rule_seq(rs, tokens, offset, rec_rules),
  rep_rule()        = parse_rep_rule(rule.rule, rule.min_count, rule.separator, rule.save_sep, tokens, offset, rec_rules),
  rule_choice(cs?)  = parse_rule_choice(cs, tokens, offset, rec_rules),
  rule_neg(r?)      = parse_rule_neg(r, tokens, offset, rec_rules),
  rule_ref(rn?)     = parse(rec_rules[rn], tokens, offset, rec_rules);


ParserResult parse_atomic_rule(TokenMatchingRule r, AnnotatedToken+ tokens, Nat offset, [Atom -> ParsingRule] rec_rules) {
  ## BAD: I'M RECONSTRUCTING THE RULE OBJECT FROM ITS PIECES (OR, RATHER, FROM ITS ONLY PIECE)
  return failure(unexpected_end_of_file(atomic_rule(r))) if not is_valid_idx(tokens, offset);
  node = tokens(offset);
  return failure(unexpected_token(node, r)) if not matches(r, node.token);
  return success(parser_match(atomic_rule_match(node), 1));
}


ParserResult parse_optional_rule(ParsingRule r, AnnotatedToken+ tokens, Nat offset, [Atom -> ParsingRule] rec_rules) {
  res = parse(r, tokens, offset, rec_rules);
  return if is_success(res) then res else success(parser_match(null_match, 0));
}


ParserResult parse_rule_seq(ParsingRule+ rs, AnnotatedToken+ tokens, Nat offset, [Atom -> ParsingRule] rec_rules) {
  matches = ();
  maybe_furthest_err = nothing;
  delta = 0;
  for r @ i <- rs {
    res = parse(r, tokens, nat(offset+delta), rec_rules);
    if is_failure(res) {
      if maybe_furthest_err != nothing {
        err = get_error(res);
        furthest_err = value(maybe_furthest_err);
        err_idx = index_of_last_matched_token(err, tokens);
        furthest_err_idx = index_of_last_matched_token(furthest_err, tokens);
        return failure(furthest_err) if furthest_err_idx > err_idx;
      }
      return res;
    }
    res = get_result(res);
    matches = matches & (res.rule_match);
    if res.failure? {
      if maybe_furthest_err == nothing {
        is_furthest = true;
      }
      else {
        curr_furthest_idx = index_of_last_matched_token(value(maybe_furthest_err), tokens);
        new_furthest_idx = index_of_last_matched_token(res.failure, tokens);
        is_furthest = new_furthest_idx > curr_furthest_idx;
      }
      maybe_furthest_err = just(res.failure) if is_furthest;
    }
    delta = nat(delta + res.nodes_consumed);
  }
  return success(parser_match(rule_seq_match(nonempty(matches)), delta, maybe_furthest_err));
}


ParserResult parse_rep_rule(ParsingRule rep_rule, Nat min_count, ParsingRule separator, Bool save_sep, AnnotatedToken+ tokens, Nat offset, [Atom -> ParsingRule] rec_rules) {
  matches = ();
  num_of_matches = 0;
  delta = 0;
  parse_res = :uninitialized; ## BUG: THIS IS HERE ONLY BECAUSE THE COMPILER WOULD OTHERWISE COMPLAIN ABOUT THE VARIABLE parse_res BEING UNDEFINED IN THE LAST LINE
  maybe_furthest_err = nothing;
  loop {
    // Matching the separator, if this is not the first match
    sep_nodes = 0;
    if matches != () {
      parse_res = parse(separator, tokens, nat(offset+delta), rec_rules);
      break if is_failure(parse_res);
      res = get_result(parse_res);
      matches = matches & (res.rule_match) if save_sep;
      sep_nodes = res.nodes_consumed;
      maybe_furthest_err = choose_error(maybe_furthest_err, res.failure, tokens) if res.failure?;
    }
    // Matching the main rule
    parse_res = parse(rep_rule, tokens, nat(offset+delta+sep_nodes), rec_rules);
    break if is_failure(parse_res);
    res = get_result(parse_res);
    matches = matches & (res.rule_match);
    num_of_matches = num_of_matches + 1;
    delta = nat(delta + sep_nodes + res.nodes_consumed);
    maybe_furthest_err = choose_error(maybe_furthest_err, res.failure, tokens) if res.failure?;
  }
  fail if parse_res == :uninitialized; ## BUG: SEE COMMENT ABOVE

  stop_err = get_error(parse_res);
  // stop_err = res;
  maybe_furthest_err = choose_error(maybe_furthest_err, stop_err, tokens);

  return parse_res if num_of_matches < min_count;
  return success(parser_match(rep_rule_match(matches), delta, value_unsafe(maybe_furthest_err)));
}


ParserResult parse_rule_choice(RuleAltern+ cs, AnnotatedToken+ tokens, Nat offset, [Atom -> ParsingRule] rec_rules) {
  errs = ();
  maybe_furthest_err = nothing;
  for c <- cs {
    res = parse(c.rule, tokens, offset, rec_rules);
    if is_success(res) {
      res = get_result(res);
      mtc = if c.name? then rule_choice_match(c.name, res.rule_match) else res.rule_match;
      maybe_furthest_err = choose_error(maybe_furthest_err, res.failure, tokens) if res.failure?;
      return success(parser_match(mtc, res.nodes_consumed, maybe_furthest_err));
    }
    else {
      err = get_error(res);
      errs = errs & (err);
      maybe_furthest_err = choose_error(maybe_furthest_err, err, tokens);
    }
  }
  ## BAD: I WOULD NEED A max_by(xs, p) FUNCTION HERE
  idx = 0;
  for e @ i <- errs
    idx = i if index_of_last_matched_token(e, tokens) > index_of_last_matched_token(errs(idx), tokens);
  ## BAD: LOSES ERROR INFORMATION HERE
  sc = cs(idx);
  res_err = if sc.name? then all_choices_failed(sc.name, errs(idx)) else errs(idx);
  return failure(res_err);
}


ParserResult parse_rule_neg(ParsingRule r, AnnotatedToken+ tokens, Nat offset, [Atom -> ParsingRule] rec_rules) {
  res = parse(r, tokens, offset, rec_rules);
  if is_failure(res)
    return success(parser_match(null_match, 0));
  else
    return failure(neg_rule_match(r, get_result(res), offset));
}

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

type FastParserRes  = no_match, (RuleMatch, Nat);


TokenMatchingRule matching_atomic_rule(PlainToken token) {
  return token if token :: LangSymb;
  return match (token)
    lowercase_id()      = lowercase_id,
    mixedcase_id()      = mixedcase_id,
    uppercase_id()      = uppercase_id,
    qualified_symbol()  = qualified_symbol,
    <*..*>              = integer,
    float_lit()         = float,
    string()            = string,
    date()              = :date,
    time()              = :time,
    operator(op?)       = operator_matching_rule(op),
    builtin()           = builtin,
    qual_var()          = qual_var,
    pref_lowercase_id() = pref_lowercase_id,
    nanoseconds()       = time_span;
}

TokenMatchingRule operator_matching_rule(UnaryOperator)   = unary_operator;
TokenMatchingRule operator_matching_rule(BinaryOperator)  = binary_operator;


implicit tokens : AnnotatedToken+, rec_rules : [Atom -> ParsingRule], tokens_count : Nat, matching_atomic_rules : TokenMatchingRule+ {
  FastParserRes fast_parse(ParsingRule rule, Nat offset) =
    empty_rule        = (null_match, 0),
    atomic_rule(r?)   = fast_parse_atomic_rule(r, offset),
    optional_rule(r?) = fast_parse_optional_rule(r, offset),
    rule_seq(rs?)     = fast_parse_rule_seq(rs, offset),
    rep_rule()        = fast_parse_rep_rule(rule.rule, rule.min_count, rule.separator, rule.save_sep, offset),
    rule_choice(cs?)  = fast_parse_rule_choice(cs, offset),
    rule_neg(r?)      = fast_parse_rule_neg(r, offset),
    rule_ref(rn?)     = fast_parse(rec_rules[rn], offset);


  FastParserRes fast_parse_atomic_rule(TokenMatchingRule r, Nat offset) {
    return :no_match if offset >= tokens_count;
    node = tokens(offset);
    is_match = match (r)
      keyword(kw?)  = {match (node.token) lowercase_id(a?) = kw == a, _ = false},
      _             = r == matching_atomic_rules(offset);
    return if is_match then (atomic_rule_match(node), 1) else :no_match;
  }


  FastParserRes fast_parse_optional_rule(ParsingRule r, Nat offset) {
    res = fast_parse(r, offset);
    return if res != :no_match then res else (null_match, 0);
  }


  FastParserRes fast_parse_rule_seq(ParsingRule+ rs, Nat offset) {
    matches = ();
    delta = 0;
    for r @ i <- rs {
      res = fast_parse(r, nat(offset+delta));
      return :no_match if res == :no_match;
      rule_match, nodes_consumed = res;
      matches = (matches | rule_match);
      delta = nat(delta + nodes_consumed);
    }
    return (rule_seq_match(nonempty(matches)), delta);
  }


  FastParserRes fast_parse_rep_rule(ParsingRule rep_rule, Nat min_count, ParsingRule separator, Bool save_sep, Nat offset) {
    matches = ();
    num_of_matches = 0;
    delta = 0;
    loop {
      // Matching the separator, if this is not the first match
      sep_nodes = 0;
      if matches != () {
        res = fast_parse(separator, nat(offset+delta));
        break if res == :no_match;
        rule_match, nodes_consumed = res;
        matches = (matches | rule_match) if save_sep;
        sep_nodes = nodes_consumed;
      }
      // Matching the main rule
      res = fast_parse(rep_rule, nat(offset+delta+sep_nodes));
      break if res == :no_match;
      rule_match, nodes_consumed = res;
      matches = (matches | rule_match);
      num_of_matches = num_of_matches + 1;
      delta = nat(delta + sep_nodes + nodes_consumed);
    }

    return :no_match if num_of_matches < min_count;
    return (rep_rule_match(matches), delta);
  }


  FastParserRes fast_parse_rule_choice(RuleAltern+ cs, Nat offset) {
    errs = ();
    for c <- cs {
      res = fast_parse(c.rule, offset);
      if res != :no_match {
        rule_match, nodes_consumed = res;
        mtc = if c.name? then rule_choice_match(c.name, rule_match) else rule_match;
        return (mtc, nodes_consumed);
      }
    }
    return :no_match;
  }


  FastParserRes fast_parse_rule_neg(ParsingRule r, Nat offset) {
    res = fast_parse(r, offset);
    if res == :no_match
      return (null_match, 0);
    else
      return :no_match;
  }
}